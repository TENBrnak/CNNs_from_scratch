{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:18.078844Z",
     "start_time": "2024-04-02T06:40:15.531538Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:18.842008Z",
     "start_time": "2024-04-02T06:40:18.838387Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read mnist data\n",
    "def read_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert int.from_bytes(data[:4], byteorder='big') == 2051\n",
    "        n_images = int.from_bytes(data[4:8], byteorder='big')\n",
    "        n_rows = int.from_bytes(data[8:12], byteorder='big')\n",
    "        n_cols = int.from_bytes(data[12:16], byteorder='big')\n",
    "        images = np.frombuffer(data, dtype=np.uint8, offset=16).reshape(n_images, n_rows, n_cols)\n",
    "        return images, n_images\n",
    "\n",
    "\n",
    "def read_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert int.from_bytes(data[:4], byteorder='big') == 2049\n",
    "        labels = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return labels\n",
    "\n",
    "\n",
    "x, num_inputs = read_mnist_images('mnist/train-images.idx3-ubyte')\n",
    "x = x.reshape((-1, 1, 28, 28))\n",
    "x = x / 255.\n",
    "y = one_hot_encode(read_mnist_labels('mnist/train-labels.idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:19.579333Z",
     "start_time": "2024-04-02T06:40:19.497064Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:20.129289Z",
     "start_time": "2024-04-02T06:40:20.125728Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        rng = np.random.default_rng()\n",
    "        variance = np.sqrt(6/(n_inputs + n_neurons))\n",
    "        self.weights = (rng.standard_normal(size=(n_inputs, n_neurons))) * variance # xavier initialization from tensorflow\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        self.dweights = np.dot(self.inputs.T, d_values) / len(self.inputs)\n",
    "        self.dbiases = np.sum(d_values, axis=0, keepdims=True) / len(self.inputs)\n",
    "        self.dinputs = np.dot(d_values, self.weights.T) / len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerConvolutional:\n",
    "    def __init__(self, num_kernels, num_channels, kernel_size):\n",
    "        rng = np.random.default_rng()\n",
    "        variance = 1/10\n",
    "        #self.weights =  0.1 * rng.standard_normal(size=(num_kernels, num_channels, kernel_size, kernel_size))\n",
    "        self.weights = (2*rng.standard_normal(size=(num_kernels, num_channels, kernel_size, kernel_size))) * variance\n",
    "        self.biases = np.zeros(num_kernels)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_kernels = num_kernels\n",
    "        self.num_channels = num_channels\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        if hasattr(self, 'output'):\n",
    "            delattr(self, 'output')\n",
    "        self.pad_size_rows = inputs.shape[-2] - (inputs.shape[-2] - self.kernel_size + 1)\n",
    "        self.pad_size_cols = inputs.shape[-1] - (inputs.shape[-1] - self.kernel_size + 1)\n",
    "        self.inputs = inputs\n",
    "        self.padded_inputs = np.pad(inputs, ((0, 0), (0, 0), (0, self.pad_size_rows), (0, self.pad_size_cols)))\n",
    "        if self.num_channels != self.inputs.shape[1]:\n",
    "            raise Exception('Error: number of filter and image channels does not match.')\n",
    "        for kernel, bias in zip(self.weights, self.biases):\n",
    "            if not hasattr(self, 'output'):\n",
    "                self.output = sp.signal.convolve(self.padded_inputs, [kernel], mode='valid') + bias\n",
    "            else:\n",
    "                self.output = np.append(self.output, sp.signal.convolve(self.padded_inputs, [kernel], mode='valid') + bias, axis=1)\n",
    "    \n",
    "    def backward(self, d_values):\n",
    "        self.dbiases = np.zeros_like(self.biases)\n",
    "        self.dinputs = np.zeros_like(self.inputs)\n",
    "        if hasattr(self, 'dweights'):\n",
    "            delattr(self, 'dweights')\n",
    "        for kernel_id in range(self.num_kernels):\n",
    "            kernel = self.weights[kernel_id]\n",
    "            rotated_kernel = np.rot90(kernel, k=2, axes=(1, 2))\n",
    "            per_kernel_dvalues = d_values[:, kernel_id:(kernel_id+1), :, :]\n",
    "            for channel_id in range(self.num_channels):\n",
    "                channel_rot_kernel = rotated_kernel[channel_id]\n",
    "                channel_inputs = self.padded_inputs[:, channel_id:channel_id+1, :, :]\n",
    "                if channel_id == 0:\n",
    "                    cur_dfilter = sp.signal.convolve(channel_inputs, per_kernel_dvalues, mode='valid').reshape((-1, 1, self.kernel_size, self.kernel_size))\n",
    "                else:\n",
    "                    cur_dfilter = np.append(cur_dfilter, sp.signal.convolve(channel_inputs, per_kernel_dvalues, mode='valid').reshape((-1, 1, self.kernel_size, self.kernel_size)), axis=1)\n",
    "                self.dinputs[:, channel_id:channel_id+1, :, :] += sp.signal.convolve(per_kernel_dvalues, [[channel_rot_kernel]], mode='full')[:, :, (self.pad_size_rows//2):-(self.pad_size_rows//2), (self.pad_size_cols//2):-(self.pad_size_cols//2)]\n",
    "            if not hasattr(self, 'dweights'):\n",
    "                self.dweights = cur_dfilter\n",
    "            else:\n",
    "                self.dweights = np.append(self.dweights, cur_dfilter, axis=0)\n",
    "            self.dbiases[kernel_id] += np.sum(per_kernel_dvalues)\n",
    "            \n",
    "            self.dbiases /= len(self.inputs)\n",
    "            self.dinputs /= len(self.inputs)\n",
    "            self.dweights /= len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:20.645775Z",
     "start_time": "2024-04-02T06:40:20.637966Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerMaxPooling:\n",
    "    def __init__(self, kernel_size=2, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        pad_cols = self.inputs.shape[-1] % self.stride if self.inputs.shape[-1] % self.stride != 0 else 0\n",
    "        pad_rows = self.inputs.shape[-2] % self.stride if self.inputs.shape[-2] % self.stride != 0 else 0\n",
    "        self.padded_inputs = np.pad(inputs, ((0, 0), (0, 0), (0, pad_rows), (0, pad_cols))) if pad_cols or pad_rows else inputs\n",
    "        self.windowed_padded_inputs = np.lib.stride_tricks.sliding_window_view(self.padded_inputs, (self.kernel_size, self.kernel_size), axis=(2, 3))[:, :, ::self.stride, ::self.stride]\n",
    "        self.output = self.windowed_padded_inputs.max(axis=(4, 5))\n",
    "        \n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = np.zeros_like(self.inputs)\n",
    "        samples, channels, rows, cols, window_rows, window_cols = self.windowed_padded_inputs.shape\n",
    "        for sample in range(samples):\n",
    "            for channel_id in range(channels):\n",
    "                for row in range(rows):\n",
    "                    for col in range(cols):\n",
    "                        window = self.windowed_padded_inputs[sample, channel_id, row, col]\n",
    "                        max_id = np.argmax(window)\n",
    "                        row_placement_in_block = max_id // window_cols\n",
    "                        col_placement_in_block = max_id % window_cols\n",
    "                        self.dinputs[sample, channel_id, window_rows*row + row_placement_in_block, window_cols*col + col_placement_in_block] = d_values[sample, channel_id, row, col]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:21.457818Z",
     "start_time": "2024-04-02T06:40:21.451124Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerFlatten:\n",
    "    def forward(self, inputs):\n",
    "        self.num_samples, self.num_channels, self.num_rows, self.num_cols = inputs.shape\n",
    "        self.output = inputs.reshape((self.num_samples, self.num_channels * self.num_rows * self.num_cols))\n",
    "    \n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = d_values.reshape((self.num_samples, self.num_channels, self.num_rows, self.num_cols))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:21.994399Z",
     "start_time": "2024-04-02T06:40:21.991517Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:22.514584Z",
     "start_time": "2024-04-02T06:40:22.511990Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = d_values.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:23.511666Z",
     "start_time": "2024-04-02T06:40:23.508710Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationSoftmaxLossCategoricalCrossentropy:\n",
    "    def forward(self, inputs, correct_labels):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True)) # -np.max(...) for numerical stability with big number\n",
    "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        predictions = np.clip(self.output, 1e-7, 1 - 1e-7)\n",
    "        loss = np.sum(-np.log(predictions) * correct_labels)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dvalues, correct_labels):\n",
    "        self.dinputs = dvalues - correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:24.240014Z",
     "start_time": "2024-04-02T06:40:24.234911Z"
    }
   },
   "outputs": [],
   "source": [
    "class OptimizerSGD:\n",
    "    def __init__(self, learning_rate=1.0, decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate \n",
    "        self.decay = decay \n",
    "        self.iterations = 0 \n",
    "        self.momentum = momentum\n",
    "\n",
    "    def pre_update_params(self): \n",
    "        if self.decay: \n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        if self.momentum: \n",
    "            if not hasattr(layer, 'weight_momentums'): \n",
    "                layer.weight_momentums = np.zeros_like(layer.weights) \n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights \n",
    "            layer.weight_momentums = weight_updates \n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases \n",
    "            layer.bias_momentums = bias_updates\n",
    "        else:\n",
    "            weight_updates = -self.learning_rate * layer.dweights\n",
    "            bias_updates = -self.learning_rate * layer.dbiases\n",
    "        \n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers=[], optimizer=None):\n",
    "        self.layers = layers\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def forward_propagation(self, x_batch, y_batch):\n",
    "        prev_layer = None\n",
    "        for layer in self.layers:\n",
    "            layer_input = x_batch if prev_layer is None else prev_layer.output\n",
    "            if isinstance(layer, ActivationSoftmaxLossCategoricalCrossentropy):\n",
    "                loss = layer.forward(layer_input, y_batch)\n",
    "            else:\n",
    "                layer.forward(layer_input)\n",
    "            prev_layer = layer\n",
    "        return loss\n",
    "    \n",
    "    def back_propagation(self, y_batch):\n",
    "        layers_reversed = self.layers[::-1]\n",
    "        prev_layer = None\n",
    "        adjustable_layers = (LayerDense, LayerConvolutional)\n",
    "        for layer in layers_reversed:\n",
    "            if isinstance(layer, ActivationSoftmaxLossCategoricalCrossentropy):\n",
    "                layer.backward(layer.output, y_batch)\n",
    "            else:\n",
    "                layer.backward(prev_layer.dinputs)\n",
    "            prev_layer = layer\n",
    "        self.optimizer.pre_update_params()\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, adjustable_layers):\n",
    "                self.optimizer.update_params(layer)\n",
    "        self.optimizer.post_update_params()\n",
    "    \n",
    "    def train(self, x, y, epochs, batch_size):\n",
    "        for i in range(epochs):\n",
    "            for j in range(0, len(x), batch_size):\n",
    "                x_batch = x[j:j+batch_size]\n",
    "                y_batch = y[j:j+batch_size]\n",
    "                loss = self.forward_propagation(x_batch, y_batch)\n",
    "                self.back_propagation(y_batch)\n",
    "                predictions = np.argmax(self.layers[-1].output, axis=1)\n",
    "                accuracy = np.mean(predictions == np.argmax(y_batch, axis=1))\n",
    "            print(f'epoch: {i}, ' + f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:25.188721Z",
     "start_time": "2024-04-02T06:40:25.184330Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST Model - Dense layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x, num_inputs = read_mnist_images('mnist/train-images.idx3-ubyte')\n",
    "x = x.reshape((-1, 1, 28, 28))\n",
    "x = x.reshape(-1, 784) / 255.\n",
    "y = one_hot_encode(read_mnist_labels('mnist/train-labels.idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:26.806670Z",
     "start_time": "2024-04-02T06:40:26.737535Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.933, loss: 12.840\n",
      "epoch: 1, acc: 0.950, loss: 11.104\n",
      "epoch: 2, acc: 0.950, loss: 10.170\n",
      "epoch: 3, acc: 0.933, loss: 9.811\n",
      "epoch: 4, acc: 0.933, loss: 9.641\n",
      "epoch: 5, acc: 0.933, loss: 9.887\n",
      "epoch: 6, acc: 0.933, loss: 10.171\n",
      "epoch: 7, acc: 0.933, loss: 9.895\n",
      "epoch: 8, acc: 0.950, loss: 9.220\n",
      "epoch: 9, acc: 0.950, loss: 8.129\n",
      "epoch: 10, acc: 0.933, loss: 7.356\n",
      "epoch: 11, acc: 0.933, loss: 6.931\n",
      "epoch: 12, acc: 0.967, loss: 6.530\n",
      "epoch: 13, acc: 0.967, loss: 5.979\n",
      "epoch: 14, acc: 0.967, loss: 5.685\n",
      "epoch: 15, acc: 0.967, loss: 5.499\n",
      "epoch: 16, acc: 0.967, loss: 5.319\n",
      "epoch: 17, acc: 0.967, loss: 4.825\n",
      "epoch: 18, acc: 0.967, loss: 4.787\n",
      "epoch: 19, acc: 0.967, loss: 4.659\n",
      "epoch: 20, acc: 0.967, loss: 4.545\n",
      "epoch: 21, acc: 0.967, loss: 4.502\n",
      "epoch: 22, acc: 0.967, loss: 4.518\n",
      "epoch: 23, acc: 0.967, loss: 4.502\n",
      "epoch: 24, acc: 0.967, loss: 4.429\n",
      "epoch: 25, acc: 0.967, loss: 4.550\n",
      "epoch: 26, acc: 0.983, loss: 4.366\n",
      "epoch: 27, acc: 0.983, loss: 4.437\n",
      "epoch: 28, acc: 0.983, loss: 4.460\n",
      "epoch: 29, acc: 0.983, loss: 4.317\n",
      "epoch: 30, acc: 0.983, loss: 4.281\n",
      "epoch: 31, acc: 0.983, loss: 4.263\n",
      "epoch: 32, acc: 0.983, loss: 4.289\n",
      "epoch: 33, acc: 0.983, loss: 4.212\n",
      "epoch: 34, acc: 0.983, loss: 4.174\n",
      "epoch: 35, acc: 0.983, loss: 4.151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m60\u001B[39m\n\u001B[1;32m      9\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m784\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mnetwork1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 41\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, x, y, epochs, batch_size)\u001B[0m\n\u001B[1;32m     39\u001B[0m x_batch \u001B[38;5;241m=\u001B[39m x[j:j\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m     40\u001B[0m y_batch \u001B[38;5;241m=\u001B[39m y[j:j\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[0;32m---> 41\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mback_propagation(y_batch)\n\u001B[1;32m     43\u001B[0m predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39moutput, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[11], line 16\u001B[0m, in \u001B[0;36mNetwork.forward_propagation\u001B[0;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[1;32m     14\u001B[0m         loss \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mforward(layer_input, y_batch)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 16\u001B[0m         \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     prev_layer \u001B[38;5;241m=\u001B[39m layer\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "Cell \u001B[0;32mIn[4], line 9\u001B[0m, in \u001B[0;36mLayerDense.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs):\n\u001B[0;32m----> 9\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbiases\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs \u001B[38;5;241m=\u001B[39m inputs\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "network1 = Network([\n",
    "    LayerDense(784, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationSoftmaxLossCategoricalCrossentropy()\n",
    "], OptimizerSGD())\n",
    "epochs = 100\n",
    "batch_size = 60\n",
    "x = x.reshape(-1, 784)\n",
    "network1.train(x, y, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:41:20.209694Z",
     "start_time": "2024-04-02T06:40:30.525853Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n",
      "Network Prediction: 6\n",
      "Correct Prediction: 6\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for test_sample_num in range(10000):\n",
    "    x_test, num_inputs = read_mnist_images('mnist/t10k-images.idx3-ubyte')\n",
    "    x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "    y_test = one_hot_encode(read_mnist_labels('mnist/t10k-labels.idx1-ubyte'), 10)\n",
    "    network1.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test)\n",
    "    pred = np.argmax(network1.layers[-1].output)\n",
    "    correct = np.argmax(y_test[test_sample_num])\n",
    "    if pred != correct:\n",
    "        count += 1\n",
    "print(f'Accuracy on eval dataset{100 - count/10000 * 100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:43:04.050878Z",
     "start_time": "2024-04-02T06:41:22.422129Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fashion MNIST model - Dense layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_fashion, num_inputs_fashion = read_mnist_images('fashion_mnist/train-images-idx3-ubyte')\n",
    "x_fashion = x_fashion.reshape(-1, 784) / 255.\n",
    "y_fashion = one_hot_encode(read_mnist_labels('fashion_mnist/train-labels-idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:43:12.860822Z",
     "start_time": "2024-04-02T06:43:12.795463Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 1.000, loss: 7.281\n",
      "epoch: 1, acc: 0.900, loss: 5.507\n",
      "epoch: 2, acc: 0.900, loss: 4.324\n",
      "epoch: 3, acc: 0.900, loss: 3.724\n",
      "epoch: 4, acc: 0.900, loss: 3.437\n",
      "epoch: 5, acc: 0.900, loss: 3.294\n",
      "epoch: 6, acc: 0.900, loss: 3.199\n",
      "epoch: 7, acc: 0.900, loss: 3.136\n",
      "epoch: 8, acc: 0.900, loss: 3.095\n",
      "epoch: 9, acc: 0.900, loss: 3.058\n",
      "epoch: 10, acc: 0.900, loss: 3.032\n",
      "epoch: 11, acc: 0.900, loss: 3.013\n",
      "epoch: 12, acc: 0.900, loss: 2.995\n",
      "epoch: 13, acc: 0.900, loss: 2.976\n",
      "epoch: 14, acc: 0.900, loss: 2.961\n",
      "epoch: 15, acc: 0.800, loss: 2.950\n",
      "epoch: 16, acc: 0.800, loss: 2.936\n",
      "epoch: 17, acc: 0.800, loss: 2.921\n",
      "epoch: 18, acc: 0.800, loss: 2.895\n",
      "epoch: 19, acc: 0.800, loss: 2.865\n",
      "epoch: 20, acc: 0.900, loss: 2.839\n",
      "epoch: 21, acc: 0.900, loss: 2.813\n",
      "epoch: 22, acc: 0.900, loss: 2.788\n",
      "epoch: 23, acc: 0.900, loss: 2.763\n",
      "epoch: 24, acc: 0.900, loss: 2.743\n",
      "epoch: 25, acc: 0.900, loss: 2.719\n",
      "epoch: 26, acc: 0.900, loss: 2.697\n",
      "epoch: 27, acc: 0.900, loss: 2.673\n",
      "epoch: 28, acc: 0.900, loss: 2.651\n",
      "epoch: 29, acc: 0.900, loss: 2.630\n"
     ]
    }
   ],
   "source": [
    "network = Network([\n",
    "    LayerDense(784, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationSoftmaxLossCategoricalCrossentropy()\n",
    "], OptimizerSGD(learning_rate=0.01))\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 10\n",
    "\n",
    "network.train(x_fashion, y_fashion, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:44:04.921064Z",
     "start_time": "2024-04-02T06:43:48.701690Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_sample_num = 301\n",
    "x_test, num_inputs = read_mnist_images('fashion_mnist/t10k-images-idx3-ubyte')\n",
    "x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "y_test = one_hot_encode(read_mnist_labels('fashion_mnist/t10k-labels-idx1-ubyte'), 10)\n",
    "network.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test)\n",
    "print(f'Network Prediction: {np.argmax(network.layers[-1].output)}')\n",
    "print(f'Correct Prediction: {np.argmax(y_test[test_sample_num])}')\n",
    "plt.imshow(x_test[test_sample_num], cmap='gray')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:45:23.401873Z",
     "start_time": "2024-04-02T06:45:23.401822Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1854\n",
      "Network Prediction: 5\n",
      "Correct Prediction: 5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for test_sample_num in range(10000):\n",
    "    x_test, num_inputs = read_mnist_images('fashion_mnist/t10k-images-idx3-ubyte')\n",
    "    x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "    y_test = one_hot_encode(read_mnist_labels('fashion_mnist/t10k-labels-idx1-ubyte'), 10)\n",
    "    network.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test)\n",
    "    pred = np.argmax(network.layers[-1].output)\n",
    "    correct = np.argmax(y_test[test_sample_num])\n",
    "    if pred != correct:\n",
    "        count += 1\n",
    "print(f'Accuracy on eval dataset{100 - count/10000 * 100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:47:08.154380Z",
     "start_time": "2024-04-02T06:45:26.532837Z"
    }
   },
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fashion MNIST model - CNN Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model  = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(784, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:32:37.490497Z",
     "start_time": "2024-04-02T06:32:37.479536Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m784\u001B[0m)              │       \u001B[38;5;34m615,440\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m10\u001B[0m)               │         \u001B[38;5;34m7,850\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m10\u001B[0m)               │           \u001B[38;5;34m110\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">615,440</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m623,402\u001B[0m (2.38 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">623,402</span> (2.38 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m623,400\u001B[0m (2.38 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">623,400</span> (2.38 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m2\u001B[0m (12.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:33:47.481859Z",
     "start_time": "2024-04-02T06:33:47.473921Z"
    }
   },
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.optimizers.sgd.SGD object at 0x15f7d7650>\n"
     ]
    }
   ],
   "source": [
    "print(model.optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:34:21.162926Z",
     "start_time": "2024-04-02T06:34:21.159792Z"
    }
   },
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 08:32:40.933721: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-04-02 08:32:40.933758: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-04-02 08:32:40.933767: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-04-02 08:32:40.934080: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-02 08:32:40.934109: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:32:41.029760Z",
     "start_time": "2024-04-02T06:32:40.927745Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_fashion, num_inputs_fashion = read_mnist_images('fashion_mnist/train-images-idx3-ubyte')\n",
    "x_fashion = x_fashion.reshape(-1, 784) / 255.\n",
    "y_fashion = one_hot_encode(read_mnist_labels('fashion_mnist/train-labels-idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:43:42.230368Z",
     "start_time": "2024-04-02T06:43:42.137432Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:559: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2024-04-02 08:32:44.486004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m3000/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 8ms/step - accuracy: 0.6642 - loss: 1.0228\n",
      "Epoch 2/20\n",
      "\u001B[1m2368/3000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m5s\u001B[0m 9ms/step - accuracy: 0.8375 - loss: 0.4724"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_fashion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_fashion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:325\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    323\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    324\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 325\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    326\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(\n\u001B[1;32m    327\u001B[0m         step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    328\u001B[0m     )\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1498\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1506\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1508\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1509\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1510\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1514\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1515\u001B[0m   )\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_fashion, y_fashion, epochs=20, batch_size=20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:33:31.032159Z",
     "start_time": "2024-04-02T06:32:44.143261Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_test, num_inputs = read_mnist_images('fashion_mnist/t10k-images-idx3-ubyte')\n",
    "x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "y_test = one_hot_encode(read_mnist_labels('fashion_mnist/t10k-labels-idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T19:51:21.896928Z",
     "start_time": "2024-03-31T19:51:21.873507Z"
    }
   },
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
