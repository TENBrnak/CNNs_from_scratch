{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:18.078844Z",
     "start_time": "2024-04-02T06:40:15.531538Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:18.842008Z",
     "start_time": "2024-04-02T06:40:18.838387Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read mnist data\n",
    "def read_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert int.from_bytes(data[:4], byteorder='big') == 2051\n",
    "        n_images = int.from_bytes(data[4:8], byteorder='big')\n",
    "        n_rows = int.from_bytes(data[8:12], byteorder='big')\n",
    "        n_cols = int.from_bytes(data[12:16], byteorder='big')\n",
    "        images = np.frombuffer(data, dtype=np.uint8, offset=16).reshape(n_images, n_rows, n_cols)\n",
    "        return images, n_images\n",
    "\n",
    "\n",
    "def read_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert int.from_bytes(data[:4], byteorder='big') == 2049\n",
    "        labels = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return labels\n",
    "\n",
    "\n",
    "x, num_inputs = read_mnist_images('mnist/train-images.idx3-ubyte')\n",
    "x = x.reshape((-1, 1, 28, 28))\n",
    "x = x / 255.\n",
    "y = one_hot_encode(read_mnist_labels('mnist/train-labels.idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:19.579333Z",
     "start_time": "2024-04-02T06:40:19.497064Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:20.129289Z",
     "start_time": "2024-04-02T06:40:20.125728Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        rng = np.random.default_rng()\n",
    "        variance = np.sqrt(6/(n_inputs + n_neurons))\n",
    "        self.weights = (rng.standard_normal(size=(n_inputs, n_neurons))) * variance # xavier initialization from tensorflow\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        self.dweights = np.dot(self.inputs.T, d_values) / len(self.inputs)\n",
    "        self.dbiases = np.sum(d_values, axis=0, keepdims=True) / len(self.inputs)\n",
    "        self.dinputs = np.dot(d_values, self.weights.T) / len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerConvolutional:\n",
    "    def __init__(self, num_kernels, num_channels, kernel_size):\n",
    "        rng = np.random.default_rng()\n",
    "        variance = 1/10\n",
    "        #self.weights =  0.1 * rng.standard_normal(size=(num_kernels, num_channels, kernel_size, kernel_size))\n",
    "        self.weights = (2*rng.standard_normal(size=(num_kernels, num_channels, kernel_size, kernel_size))) * variance\n",
    "        self.biases = np.zeros(num_kernels)\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_kernels = num_kernels\n",
    "        self.num_channels = num_channels\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        if hasattr(self, 'output'):\n",
    "            delattr(self, 'output')\n",
    "        self.pad_size_rows = inputs.shape[-2] - (inputs.shape[-2] - self.kernel_size + 1)\n",
    "        self.pad_size_cols = inputs.shape[-1] - (inputs.shape[-1] - self.kernel_size + 1)\n",
    "        self.inputs = inputs\n",
    "        self.padded_inputs = np.pad(inputs, ((0, 0), (0, 0), (0, self.pad_size_rows), (0, self.pad_size_cols)))\n",
    "        if self.num_channels != self.inputs.shape[1]:\n",
    "            raise Exception('Error: number of filter and image channels does not match.')\n",
    "        for kernel, bias in zip(self.weights, self.biases):\n",
    "            if not hasattr(self, 'output'):\n",
    "                self.output = sp.signal.convolve(self.padded_inputs, [kernel], mode='valid') + bias\n",
    "            else:\n",
    "                self.output = np.append(self.output, sp.signal.convolve(self.padded_inputs, [kernel], mode='valid') + bias, axis=1)\n",
    "    \n",
    "    def backward(self, d_values):\n",
    "        self.dbiases = np.zeros_like(self.biases)\n",
    "        self.dinputs = np.zeros_like(self.inputs)\n",
    "        if hasattr(self, 'dweights'):\n",
    "            delattr(self, 'dweights')\n",
    "        for kernel_id in range(self.num_kernels):\n",
    "            kernel = self.weights[kernel_id]\n",
    "            rotated_kernel = np.rot90(kernel, k=2, axes=(1, 2))\n",
    "            per_kernel_dvalues = d_values[:, kernel_id:(kernel_id+1), :, :]\n",
    "            for channel_id in range(self.num_channels):\n",
    "                channel_rot_kernel = rotated_kernel[channel_id]\n",
    "                channel_inputs = self.padded_inputs[:, channel_id:channel_id+1, :, :]\n",
    "                if channel_id == 0:\n",
    "                    cur_dfilter = sp.signal.convolve(channel_inputs, per_kernel_dvalues, mode='valid').reshape((-1, 1, self.kernel_size, self.kernel_size))\n",
    "                else:\n",
    "                    cur_dfilter = np.append(cur_dfilter, sp.signal.convolve(channel_inputs, per_kernel_dvalues, mode='valid').reshape((-1, 1, self.kernel_size, self.kernel_size)), axis=1)\n",
    "                self.dinputs[:, channel_id:channel_id+1, :, :] += sp.signal.convolve(per_kernel_dvalues, [[channel_rot_kernel]], mode='full')[:, :, (self.pad_size_rows//2):-(self.pad_size_rows//2), (self.pad_size_cols//2):-(self.pad_size_cols//2)]\n",
    "            if not hasattr(self, 'dweights'):\n",
    "                self.dweights = cur_dfilter\n",
    "            else:\n",
    "                self.dweights = np.append(self.dweights, cur_dfilter, axis=0)\n",
    "            self.dbiases[kernel_id] += np.sum(per_kernel_dvalues)\n",
    "            \n",
    "            self.dbiases /= len(self.inputs)\n",
    "            self.dinputs /= len(self.inputs)\n",
    "            self.dweights /= len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:20.645775Z",
     "start_time": "2024-04-02T06:40:20.637966Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerMaxPooling:\n",
    "    def __init__(self, kernel_size=2, stride=2):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        pad_cols = self.inputs.shape[-1] % self.stride if self.inputs.shape[-1] % self.stride != 0 else 0\n",
    "        pad_rows = self.inputs.shape[-2] % self.stride if self.inputs.shape[-2] % self.stride != 0 else 0\n",
    "        self.padded_inputs = np.pad(inputs, ((0, 0), (0, 0), (0, pad_rows), (0, pad_cols))) if pad_cols or pad_rows else inputs\n",
    "        self.windowed_padded_inputs = np.lib.stride_tricks.sliding_window_view(self.padded_inputs, (self.kernel_size, self.kernel_size), axis=(2, 3))[:, :, ::self.stride, ::self.stride]\n",
    "        self.output = self.windowed_padded_inputs.max(axis=(4, 5))\n",
    "        \n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = np.zeros_like(self.inputs)\n",
    "        samples, channels, rows, cols, window_rows, window_cols = self.windowed_padded_inputs.shape\n",
    "        for sample in range(samples):\n",
    "            for channel_id in range(channels):\n",
    "                for row in range(rows):\n",
    "                    for col in range(cols):\n",
    "                        window = self.windowed_padded_inputs[sample, channel_id, row, col]\n",
    "                        max_id = np.argmax(window)\n",
    "                        row_placement_in_block = max_id // window_cols\n",
    "                        col_placement_in_block = max_id % window_cols\n",
    "                        self.dinputs[sample, channel_id, window_rows*row + row_placement_in_block, window_cols*col + col_placement_in_block] = d_values[sample, channel_id, row, col]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:21.457818Z",
     "start_time": "2024-04-02T06:40:21.451124Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerFlatten:\n",
    "    def forward(self, inputs):\n",
    "        self.num_samples, self.num_channels, self.num_rows, self.num_cols = inputs.shape\n",
    "        self.output = inputs.reshape((self.num_samples, self.num_channels * self.num_rows * self.num_cols))\n",
    "    \n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = d_values.reshape((self.num_samples, self.num_channels, self.num_rows, self.num_cols))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:21.994399Z",
     "start_time": "2024-04-02T06:40:21.991517Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:22.514584Z",
     "start_time": "2024-04-02T06:40:22.511990Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = d_values.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:23.511666Z",
     "start_time": "2024-04-02T06:40:23.508710Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationSoftmaxLossCategoricalCrossentropy:\n",
    "    def forward(self, inputs, correct_labels):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True)) # -np.max(...) for numerical stability with big number\n",
    "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        predictions = np.clip(self.output, 1e-7, 1 - 1e-7)\n",
    "        loss = np.sum(-np.log(predictions) * correct_labels)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dvalues, correct_labels):\n",
    "        self.dinputs = dvalues - correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:24.240014Z",
     "start_time": "2024-04-02T06:40:24.234911Z"
    }
   },
   "outputs": [],
   "source": [
    "class OptimizerSGD:\n",
    "    def __init__(self, learning_rate=1.0, decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate \n",
    "        self.decay = decay \n",
    "        self.iterations = 0 \n",
    "        self.momentum = momentum\n",
    "\n",
    "    def pre_update_params(self): \n",
    "        if self.decay: \n",
    "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        if self.momentum: \n",
    "            if not hasattr(layer, 'weight_momentums'): \n",
    "                layer.weight_momentums = np.zeros_like(layer.weights) \n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            \n",
    "            weight_updates = self.momentum * layer.weight_momentums - self.current_learning_rate * layer.dweights \n",
    "            layer.weight_momentums = weight_updates \n",
    "            bias_updates = self.momentum * layer.bias_momentums - self.current_learning_rate * layer.dbiases \n",
    "            layer.bias_momentums = bias_updates\n",
    "        else:\n",
    "            weight_updates = -self.learning_rate * layer.dweights\n",
    "            bias_updates = -self.learning_rate * layer.dbiases\n",
    "        \n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers=[], optimizer=None):\n",
    "        self.layers = layers\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def forward_propagation(self, x_batch, y_batch):\n",
    "        prev_layer = None\n",
    "        for layer in self.layers:\n",
    "            layer_input = x_batch if prev_layer is None else prev_layer.output\n",
    "            if isinstance(layer, ActivationSoftmaxLossCategoricalCrossentropy):\n",
    "                loss = layer.forward(layer_input, y_batch)\n",
    "            else:\n",
    "                layer.forward(layer_input)\n",
    "            prev_layer = layer\n",
    "        return loss\n",
    "    \n",
    "    def back_propagation(self, y_batch):\n",
    "        layers_reversed = self.layers[::-1]\n",
    "        prev_layer = None\n",
    "        adjustable_layers = (LayerDense, LayerConvolutional)\n",
    "        for layer in layers_reversed:\n",
    "            if isinstance(layer, ActivationSoftmaxLossCategoricalCrossentropy):\n",
    "                layer.backward(layer.output, y_batch)\n",
    "            else:\n",
    "                layer.backward(prev_layer.dinputs)\n",
    "            prev_layer = layer\n",
    "        self.optimizer.pre_update_params()\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, adjustable_layers):\n",
    "                self.optimizer.update_params(layer)\n",
    "        self.optimizer.post_update_params()\n",
    "    \n",
    "    def train(self, x, y, epochs, batch_size):\n",
    "        for i in range(epochs):\n",
    "            for j in range(0, len(x), batch_size):\n",
    "                x_batch = x[j:j+batch_size]\n",
    "                y_batch = y[j:j+batch_size]\n",
    "                loss = self.forward_propagation(x_batch, y_batch)\n",
    "                self.back_propagation(y_batch)\n",
    "                predictions = np.argmax(self.layers[-1].output, axis=1)\n",
    "                accuracy = np.mean(predictions == np.argmax(y_batch, axis=1))\n",
    "            print(f'epoch: {i}, ' + f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:25.188721Z",
     "start_time": "2024-04-02T06:40:25.184330Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST Model - Dense layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x, num_inputs = read_mnist_images('mnist/train-images.idx3-ubyte')\n",
    "x = x.reshape((-1, 1, 28, 28))\n",
    "x = x.reshape(-1, 784) / 255.\n",
    "y = one_hot_encode(read_mnist_labels('mnist/train-labels.idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:40:26.806670Z",
     "start_time": "2024-04-02T06:40:26.737535Z"
    }
   },
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.933, loss: 12.840\n",
      "epoch: 1, acc: 0.950, loss: 11.104\n",
      "epoch: 2, acc: 0.950, loss: 10.170\n",
      "epoch: 3, acc: 0.933, loss: 9.811\n",
      "epoch: 4, acc: 0.933, loss: 9.641\n",
      "epoch: 5, acc: 0.933, loss: 9.887\n",
      "epoch: 6, acc: 0.933, loss: 10.171\n",
      "epoch: 7, acc: 0.933, loss: 9.895\n",
      "epoch: 8, acc: 0.950, loss: 9.220\n",
      "epoch: 9, acc: 0.950, loss: 8.129\n",
      "epoch: 10, acc: 0.933, loss: 7.356\n",
      "epoch: 11, acc: 0.933, loss: 6.931\n",
      "epoch: 12, acc: 0.967, loss: 6.530\n",
      "epoch: 13, acc: 0.967, loss: 5.979\n",
      "epoch: 14, acc: 0.967, loss: 5.685\n",
      "epoch: 15, acc: 0.967, loss: 5.499\n",
      "epoch: 16, acc: 0.967, loss: 5.319\n",
      "epoch: 17, acc: 0.967, loss: 4.825\n",
      "epoch: 18, acc: 0.967, loss: 4.787\n",
      "epoch: 19, acc: 0.967, loss: 4.659\n",
      "epoch: 20, acc: 0.967, loss: 4.545\n",
      "epoch: 21, acc: 0.967, loss: 4.502\n",
      "epoch: 22, acc: 0.967, loss: 4.518\n",
      "epoch: 23, acc: 0.967, loss: 4.502\n",
      "epoch: 24, acc: 0.967, loss: 4.429\n",
      "epoch: 25, acc: 0.967, loss: 4.550\n",
      "epoch: 26, acc: 0.983, loss: 4.366\n",
      "epoch: 27, acc: 0.983, loss: 4.437\n",
      "epoch: 28, acc: 0.983, loss: 4.460\n",
      "epoch: 29, acc: 0.983, loss: 4.317\n",
      "epoch: 30, acc: 0.983, loss: 4.281\n",
      "epoch: 31, acc: 0.983, loss: 4.263\n",
      "epoch: 32, acc: 0.983, loss: 4.289\n",
      "epoch: 33, acc: 0.983, loss: 4.212\n",
      "epoch: 34, acc: 0.983, loss: 4.174\n",
      "epoch: 35, acc: 0.983, loss: 4.151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m60\u001B[39m\n\u001B[1;32m      9\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m784\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m \u001B[43mnetwork1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 41\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, x, y, epochs, batch_size)\u001B[0m\n\u001B[1;32m     39\u001B[0m x_batch \u001B[38;5;241m=\u001B[39m x[j:j\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m     40\u001B[0m y_batch \u001B[38;5;241m=\u001B[39m y[j:j\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[0;32m---> 41\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mback_propagation(y_batch)\n\u001B[1;32m     43\u001B[0m predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39moutput, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[11], line 16\u001B[0m, in \u001B[0;36mNetwork.forward_propagation\u001B[0;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[1;32m     14\u001B[0m         loss \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mforward(layer_input, y_batch)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 16\u001B[0m         \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     prev_layer \u001B[38;5;241m=\u001B[39m layer\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "Cell \u001B[0;32mIn[4], line 9\u001B[0m, in \u001B[0;36mLayerDense.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs):\n\u001B[0;32m----> 9\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbiases\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs \u001B[38;5;241m=\u001B[39m inputs\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "network_mnist_dense = Network([\n",
    "    LayerDense(784, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationSoftmaxLossCategoricalCrossentropy()\n",
    "], OptimizerSGD())\n",
    "epochs = 100\n",
    "batch_size = 60\n",
    "x = x.reshape(-1, 784)\n",
    "network_mnist_dense.train(x, y, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:41:20.209694Z",
     "start_time": "2024-04-02T06:40:30.525853Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n",
      "Network Prediction: 6\n",
      "Correct Prediction: 6\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "x_test, num_inputs = read_mnist_images('mnist/t10k-images.idx3-ubyte')\n",
    "y_test = one_hot_encode(read_mnist_labels('mnist/t10k-labels.idx1-ubyte'), 10)\n",
    "for test_sample_num in range(num_inputs):\n",
    "    x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "    network_mnist_dense.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test[test_sample_num:test_sample_num+1])\n",
    "    pred = np.argmax(network_mnist_dense.layers[-1].output)\n",
    "    correct = np.argmax(y_test[test_sample_num])\n",
    "    if pred != correct:\n",
    "        count += 1\n",
    "print(f'Accuracy on eval dataset{100 - count/num_inputs * 100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:43:04.050878Z",
     "start_time": "2024-04-02T06:41:22.422129Z"
    }
   },
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fashion MNIST model - Dense layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_fashion, num_inputs_fashion = read_mnist_images('fashion_mnist/train-images-idx3-ubyte')\n",
    "x_fashion_flat = x_fashion.reshape(-1, 784) / 255.\n",
    "y_fashion = one_hot_encode(read_mnist_labels('fashion_mnist/train-labels-idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:43:12.860822Z",
     "start_time": "2024-04-02T06:43:12.795463Z"
    }
   },
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 1.000, loss: 7.281\n",
      "epoch: 1, acc: 0.900, loss: 5.507\n",
      "epoch: 2, acc: 0.900, loss: 4.324\n",
      "epoch: 3, acc: 0.900, loss: 3.724\n",
      "epoch: 4, acc: 0.900, loss: 3.437\n",
      "epoch: 5, acc: 0.900, loss: 3.294\n",
      "epoch: 6, acc: 0.900, loss: 3.199\n",
      "epoch: 7, acc: 0.900, loss: 3.136\n",
      "epoch: 8, acc: 0.900, loss: 3.095\n",
      "epoch: 9, acc: 0.900, loss: 3.058\n",
      "epoch: 10, acc: 0.900, loss: 3.032\n",
      "epoch: 11, acc: 0.900, loss: 3.013\n",
      "epoch: 12, acc: 0.900, loss: 2.995\n",
      "epoch: 13, acc: 0.900, loss: 2.976\n",
      "epoch: 14, acc: 0.900, loss: 2.961\n",
      "epoch: 15, acc: 0.800, loss: 2.950\n",
      "epoch: 16, acc: 0.800, loss: 2.936\n",
      "epoch: 17, acc: 0.800, loss: 2.921\n",
      "epoch: 18, acc: 0.800, loss: 2.895\n",
      "epoch: 19, acc: 0.800, loss: 2.865\n",
      "epoch: 20, acc: 0.900, loss: 2.839\n",
      "epoch: 21, acc: 0.900, loss: 2.813\n",
      "epoch: 22, acc: 0.900, loss: 2.788\n",
      "epoch: 23, acc: 0.900, loss: 2.763\n",
      "epoch: 24, acc: 0.900, loss: 2.743\n",
      "epoch: 25, acc: 0.900, loss: 2.719\n",
      "epoch: 26, acc: 0.900, loss: 2.697\n",
      "epoch: 27, acc: 0.900, loss: 2.673\n",
      "epoch: 28, acc: 0.900, loss: 2.651\n",
      "epoch: 29, acc: 0.900, loss: 2.630\n"
     ]
    }
   ],
   "source": [
    "network_fashion_dense = Network([\n",
    "    LayerDense(784, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationSoftmaxLossCategoricalCrossentropy()\n",
    "], OptimizerSGD(learning_rate=0.01))\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 10\n",
    "\n",
    "network_fashion_dense.train(x_fashion_flat, y_fashion, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:44:04.921064Z",
     "start_time": "2024-04-02T06:43:48.701690Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_sample_num = 301\n",
    "x_test, num_inputs = read_mnist_images('fashion_mnist/t10k-images-idx3-ubyte')\n",
    "x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "y_test = one_hot_encode(read_mnist_labels('fashion_mnist/t10k-labels-idx1-ubyte'), 10)\n",
    "network.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test)\n",
    "print(f'Network Prediction: {np.argmax(network.layers[-1].output)}')\n",
    "print(f'Correct Prediction: {np.argmax(y_test[test_sample_num])}')\n",
    "plt.imshow(x_test[test_sample_num], cmap='gray')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:45:23.401873Z",
     "start_time": "2024-04-02T06:45:23.401822Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (4,2)  and requested shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m test_sample_num \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_inputs):\n\u001B[1;32m      5\u001B[0m     x_test_flat \u001B[38;5;241m=\u001B[39m x_test\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m784\u001B[39m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255.\u001B[39m\n\u001B[0;32m----> 6\u001B[0m     \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_test_flat\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_sample_num\u001B[49m\u001B[43m:\u001B[49m\u001B[43mtest_sample_num\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtest_sample_num\u001B[49m\u001B[43m:\u001B[49m\u001B[43mtest_sample_num\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     pred \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(network\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39moutput)\n\u001B[1;32m      8\u001B[0m     correct \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_test[test_sample_num])\n",
      "Cell \u001B[0;32mIn[11], line 16\u001B[0m, in \u001B[0;36mNetwork.forward_propagation\u001B[0;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[1;32m     14\u001B[0m         loss \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mforward(layer_input, y_batch)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 16\u001B[0m         \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     prev_layer \u001B[38;5;241m=\u001B[39m layer\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "Cell \u001B[0;32mIn[5], line 18\u001B[0m, in \u001B[0;36mLayerConvolutional.forward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_size_cols \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m (inputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel_size \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs \u001B[38;5;241m=\u001B[39m inputs\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadded_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_size_rows\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_size_cols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_channels \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError: number of filter and image channels does not match.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/numpy/lib/arraypad.py:748\u001B[0m, in \u001B[0;36mpad\u001B[0;34m(array, pad_width, mode, **kwargs)\u001B[0m\n\u001B[1;32m    745\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`pad_width` must be of integral type.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    747\u001B[0m \u001B[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001B[39;00m\n\u001B[0;32m--> 748\u001B[0m pad_width \u001B[38;5;241m=\u001B[39m \u001B[43m_as_pairs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpad_width\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    750\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(mode):\n\u001B[1;32m    751\u001B[0m     \u001B[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001B[39;00m\n\u001B[1;32m    752\u001B[0m     function \u001B[38;5;241m=\u001B[39m mode\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/numpy/lib/arraypad.py:522\u001B[0m, in \u001B[0;36m_as_pairs\u001B[0;34m(x, ndim, as_index)\u001B[0m\n\u001B[1;32m    518\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt contain negative values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    520\u001B[0m \u001B[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001B[39;00m\n\u001B[1;32m    521\u001B[0m \u001B[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001B[39;00m\n\u001B[0;32m--> 522\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/numpy/lib/stride_tricks.py:413\u001B[0m, in \u001B[0;36mbroadcast_to\u001B[0;34m(array, shape, subok)\u001B[0m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_broadcast_to_dispatcher, module\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbroadcast_to\u001B[39m(array, shape, subok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    369\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001B[39;00m\n\u001B[1;32m    370\u001B[0m \n\u001B[1;32m    371\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    411\u001B[0m \u001B[38;5;124;03m           [1, 2, 3]])\u001B[39;00m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 413\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_broadcast_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubok\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreadonly\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/numpy/lib/stride_tricks.py:349\u001B[0m, in \u001B[0;36m_broadcast_to\u001B[0;34m(array, shape, subok, readonly)\u001B[0m\n\u001B[1;32m    346\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall elements of broadcast shape must be non-\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    347\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    348\u001B[0m extras \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 349\u001B[0m it \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnditer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmulti_index\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrefs_ok\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mzerosize_ok\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mextras\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mop_flags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreadonly\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitershape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m it:\n\u001B[1;32m    353\u001B[0m     \u001B[38;5;66;03m# never really has writebackifcopy semantics\u001B[39;00m\n\u001B[1;32m    354\u001B[0m     broadcast \u001B[38;5;241m=\u001B[39m it\u001B[38;5;241m.\u001B[39mitviews[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (4,2)  and requested shape (2,2)"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "x_test, num_inputs = read_mnist_images('fashion_mnist/t10k-images-idx3-ubyte')\n",
    "y_test = one_hot_encode(read_mnist_labels('fashion_mnist/t10k-labels-idx1-ubyte'), 10)\n",
    "for test_sample_num in range(num_inputs):\n",
    "    x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "    network_fashion_dense.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test[test_sample_num:test_sample_num+1])\n",
    "    pred = np.argmax(network_fashion_dense.layers[-1].output)\n",
    "    correct = np.argmax(y_test[test_sample_num])\n",
    "    if pred != correct:\n",
    "        count += 1\n",
    "print(f'Accuracy on eval dataset: {100 - count/num_inputs * 100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:07.193595Z",
     "start_time": "2024-04-02T07:39:07.124738Z"
    }
   },
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fashion MNIST model - CNN Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_fashion_image_reshaped = x_fashion.reshape(-1, 1, 28, 28) / 255."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:55:36.961068Z",
     "start_time": "2024-04-02T06:55:36.881481Z"
    }
   },
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.500, loss: 16.308\n",
      "epoch: 1, acc: 0.700, loss: 12.115\n",
      "epoch: 2, acc: 0.700, loss: 9.881\n",
      "epoch: 3, acc: 0.600, loss: 8.486\n",
      "epoch: 4, acc: 0.600, loss: 7.506\n",
      "epoch: 5, acc: 0.600, loss: 6.782\n",
      "epoch: 6, acc: 0.700, loss: 6.207\n",
      "epoch: 7, acc: 0.800, loss: 5.735\n",
      "epoch: 8, acc: 0.800, loss: 5.345\n",
      "epoch: 9, acc: 0.800, loss: 5.022\n",
      "epoch: 10, acc: 0.800, loss: 4.755\n",
      "epoch: 11, acc: 0.800, loss: 4.536\n",
      "epoch: 12, acc: 0.800, loss: 4.359\n",
      "epoch: 13, acc: 0.800, loss: 4.215\n",
      "epoch: 14, acc: 0.800, loss: 4.100\n",
      "epoch: 15, acc: 0.800, loss: 3.999\n",
      "epoch: 16, acc: 0.800, loss: 3.914\n",
      "epoch: 17, acc: 0.900, loss: 3.846\n",
      "epoch: 18, acc: 0.900, loss: 3.803\n",
      "epoch: 19, acc: 0.900, loss: 3.795\n",
      "epoch: 20, acc: 0.800, loss: 3.756\n",
      "epoch: 21, acc: 0.800, loss: 3.683\n",
      "epoch: 22, acc: 0.800, loss: 3.598\n",
      "epoch: 23, acc: 0.800, loss: 3.511\n",
      "epoch: 24, acc: 0.800, loss: 3.445\n",
      "epoch: 25, acc: 0.800, loss: 3.457\n",
      "epoch: 26, acc: 0.800, loss: 3.500\n",
      "epoch: 27, acc: 0.800, loss: 3.532\n",
      "epoch: 28, acc: 0.800, loss: 3.553\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m30\u001B[39m\n\u001B[1;32m     14\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m---> 16\u001B[0m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_fashion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_fashion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 42\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, x, y, epochs, batch_size)\u001B[0m\n\u001B[1;32m     40\u001B[0m y_batch \u001B[38;5;241m=\u001B[39m y[j:j\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m     41\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_propagation(x_batch, y_batch)\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mback_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39moutput, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     44\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(predictions \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_batch, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "Cell \u001B[0;32mIn[11], line 28\u001B[0m, in \u001B[0;36mNetwork.back_propagation\u001B[0;34m(self, y_batch)\u001B[0m\n\u001B[1;32m     26\u001B[0m         layer\u001B[38;5;241m.\u001B[39mbackward(layer\u001B[38;5;241m.\u001B[39moutput, y_batch)\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 28\u001B[0m         \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprev_layer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdinputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     prev_layer \u001B[38;5;241m=\u001B[39m layer\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mpre_update_params()\n",
      "Cell \u001B[0;32mIn[6], line 22\u001B[0m, in \u001B[0;36mLayerMaxPooling.backward\u001B[0;34m(self, d_values)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(cols):\n\u001B[1;32m     21\u001B[0m     window \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindowed_padded_inputs[sample, channel_id, row, col]\n\u001B[0;32m---> 22\u001B[0m     max_id \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwindow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     row_placement_in_block \u001B[38;5;241m=\u001B[39m max_id \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m window_cols\n\u001B[1;32m     24\u001B[0m     col_placement_in_block \u001B[38;5;241m=\u001B[39m max_id \u001B[38;5;241m%\u001B[39m window_cols\n",
      "File \u001B[0;32m/opt/homebrew/anaconda3/envs/NNFS/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1140\u001B[0m, in \u001B[0;36margmax\u001B[0;34m(a, axis, out, keepdims)\u001B[0m\n\u001B[1;32m   1136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_argmax_dispatcher\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n\u001B[1;32m   1137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, out)\n\u001B[0;32m-> 1140\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_argmax_dispatcher)\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21margmax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;124;03m    Returns the indices of the maximum values along an axis.\u001B[39;00m\n\u001B[1;32m   1144\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;124;03m    (2, 1, 4)\u001B[39;00m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m     kwds \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkeepdims\u001B[39m\u001B[38;5;124m'\u001B[39m: keepdims} \u001B[38;5;28;01mif\u001B[39;00m keepdims \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39m_NoValue \u001B[38;5;28;01melse\u001B[39;00m {}\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "network = Network([\n",
    "    LayerConvolutional(2, 1, 3),\n",
    "    LayerMaxPooling(),\n",
    "    LayerConvolutional(3, 2, 3),\n",
    "    LayerMaxPooling(),\n",
    "    LayerFlatten(),\n",
    "    LayerDense(147, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationSoftmaxLossCategoricalCrossentropy()\n",
    "], OptimizerSGD(learning_rate=0.01))\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 10\n",
    "\n",
    "network.train(x_fashion_image_reshaped, y_fashion, epochs, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:36:32.215052Z",
     "start_time": "2024-04-02T06:56:55.852680Z"
    }
   },
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval dataset78.34\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "x_test, num_inputs = read_mnist_images('fashion_mnist/t10k-images-idx3-ubyte')\n",
    "y_test = one_hot_encode(read_mnist_labels('fashion_mnist/t10k-labels-idx1-ubyte'), 10)\n",
    "for test_sample_num in range(num_inputs):\n",
    "    x_test_flat = x_test.reshape(-1, 1, 28, 28) / 255.\n",
    "    network.forward_propagation(x_test_flat[test_sample_num:test_sample_num+1, :], y_test[test_sample_num:test_sample_num+1])\n",
    "    pred = np.argmax(network.layers[-1].output)\n",
    "    correct = np.argmax(y_test[test_sample_num])\n",
    "    if pred != correct:\n",
    "        count += 1\n",
    "print(f'Accuracy on eval dataset: {100 - count/num_inputs * 100}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:38:47.295272Z",
     "start_time": "2024-04-02T07:37:16.612571Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
