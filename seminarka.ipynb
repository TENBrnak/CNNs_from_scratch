{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:39:43.985247Z",
     "start_time": "2024-03-23T09:39:43.406335Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:39:43.987816Z",
     "start_time": "2024-03-23T09:39:43.986170Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read mnist data\n",
    "def read_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert int.from_bytes(data[:4], byteorder='big') == 2051\n",
    "        n_images = int.from_bytes(data[4:8], byteorder='big')\n",
    "        n_rows = int.from_bytes(data[8:12], byteorder='big')\n",
    "        n_cols = int.from_bytes(data[12:16], byteorder='big')\n",
    "        images = np.frombuffer(data, dtype=np.uint8, offset=16).reshape(n_images, n_rows, n_cols)\n",
    "        return images, n_images\n",
    "\n",
    "\n",
    "def read_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert int.from_bytes(data[:4], byteorder='big') == 2049\n",
    "        labels = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "        return labels\n",
    "\n",
    "\n",
    "x, num_inputs = read_mnist_images('mnist/train-images.idx3-ubyte')\n",
    "x = x.reshape((-1, 1, 28, 28))\n",
    "x = x / 255.\n",
    "y = one_hot_encode(read_mnist_labels('mnist/train-labels.idx1-ubyte'), 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:54:10.750887Z",
     "start_time": "2024-03-23T09:54:10.670078Z"
    }
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "kernels = np.random.rand(3, 1, 3, 3) - 0.5\n",
    "kernels = np.array([[[\n",
    "    [1, 1, 1], \n",
    "    [0, 0, 0], \n",
    "    [-1, -1, -2]]], [[[1, 1, 1], [0, 0, 0], [-1, -1, -3]]], [[[1, 1, 1], [0, 0, 0], [-1, -1, -1]]]])\n",
    "\n",
    "conv = LayerConvolutional(3, 2, 1)\n",
    "conv2 = LayerConvolutional(3, 3, 2)\n",
    "conv.forward(x[:5])\n",
    "conv2.forward(conv.output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:42:03.820182Z",
     "start_time": "2024-03-25T17:42:03.811083Z"
    }
   },
   "execution_count": 262
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conv2.backward(conv2.output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:42:04.852597Z",
     "start_time": "2024-03-25T17:42:04.840763Z"
    }
   },
   "execution_count": 263
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(5, 2, 28, 28)"
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2.dinputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:42:10.628446Z",
     "start_time": "2024-03-25T17:42:10.625540Z"
    }
   },
   "execution_count": 264
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T21:14:28.863855Z",
     "start_time": "2024-03-23T21:14:28.858255Z"
    }
   },
   "outputs": [],
   "source": [
    "class LayerDense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = np.random.rand(n_inputs, n_neurons) - 0.5\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        self.dweights = np.dot(self.inputs.T, d_values) / len(self.inputs)\n",
    "        self.dbiases = np.sum(d_values, axis=0, keepdims=True) / len(self.inputs)\n",
    "        self.dinputs = np.dot(d_values, self.weights.T) / len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerConvolutional:\n",
    "    def __init__(self, kernel_size, num_kernels, num_channels):\n",
    "        self.filters =  np.random.rand(num_kernels, num_channels, kernel_size, kernel_size) - 0.5\n",
    "        self.biases = np.zeros(num_kernels)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self.pad_size_rows = inputs.shape[-2] - (inputs.shape[-2] - self.filters.shape[-2] + 1)\n",
    "        self.pad_size_cols = inputs.shape[-1] - (inputs.shape[-1] - self.filters.shape[-1] + 1)\n",
    "        self.inputs = inputs\n",
    "        self.padded_inputs = np.pad(inputs, ((0, 0), (0, 0), (0, self.pad_size_rows), (0, self.pad_size_cols)))\n",
    "        if self.filters.shape[1] != self.inputs.shape[1]:\n",
    "            raise 'Error: number of filter and image channels does not match.'\n",
    "        for kernel, bias in zip(self.filters, self.biases):\n",
    "            if not hasattr(self, 'output'):\n",
    "                self.output = sp.signal.convolve(self.padded_inputs, [kernel], mode='valid') + bias\n",
    "            else:\n",
    "                self.output = np.append(self.output, sp.signal.convolve(self.padded_inputs, [kernel], mode='valid') + bias, axis=1)\n",
    "                \n",
    "    def backward(self, d_values):\n",
    "        self.dbiases = np.zeros_like(self.biases)\n",
    "        self.dinputs = np.zeros_like(self.inputs)\n",
    "        for kernel_id in range(len(self.filters)):\n",
    "            rotated_kernel = np.rot90(self.filters[kernel_id], k=2, axes=(1, 2))\n",
    "            num_channels = len(kernel)\n",
    "            corresponding_dvalues = d_values[:, kernel_id*num_channels:(kernel_id+1)*num_channels, :, :]\n",
    "            if not hasattr(self, 'dfilters'):\n",
    "                self.dfilters = sp.signal.convolve(self.padded_inputs, corresponding_dvalues, mode='valid')\n",
    "            else:\n",
    "                self.dfilters = np.append(self.dfilters, sp.signal.convolve(self.padded_inputs, corresponding_dvalues, mode='valid'), axis=0)\n",
    "            self.dinputs += sp.signal.convolve(corresponding_dvalues, [rotated_kernel], mode='full')[:, :, (self.pad_size_rows//2):-(self.pad_size_rows//2), (self.pad_size_cols//2):-(self.pad_size_cols//2)]\n",
    "            self.dbiases[kernel_id] += np.sum(corresponding_dvalues)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T17:42:00.803203Z",
     "start_time": "2024-03-25T17:42:00.792919Z"
    }
   },
   "execution_count": 261
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LayerMaxPooling:\n",
    "    def __init__(self, kernel_size):\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    def backward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T09:40:58.213783Z",
     "start_time": "2024-03-19T09:40:58.210771Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def backward(self, d_values):\n",
    "        self.dinputs = d_values.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T09:40:58.649030Z",
     "start_time": "2024-03-19T09:40:58.646044Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActivationSoftmaxLossCategoricalCrossentropy:\n",
    "    def forward(self, inputs, correct_labels):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True)) # -np.max(...) for numerical stability with big number\n",
    "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        predictions = np.clip(self.output, 1e-7, 1 - 1e-7)\n",
    "        loss = np.sum(-np.log(predictions) * correct_labels)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dvalues, correct_labels):\n",
    "        self.dinputs = dvalues - correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T09:40:59.051840Z",
     "start_time": "2024-03-19T09:40:59.048576Z"
    }
   },
   "outputs": [],
   "source": [
    "class OptimizerSGD:\n",
    "    def __init__(self, learning_rate=1.0):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def update_params(self, layer):\n",
    "        \n",
    "        weight_updates = -self.learning_rate * layer.dweights\n",
    "        bias_updates = -self.learning_rate * layer.dbiases\n",
    "        \n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, layers=[], optimizer=None):\n",
    "        self.layers = layers\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def forward_propagation(self, x_batch, y_batch):\n",
    "        prev_layer = None\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayerDense):\n",
    "                layer_input = x_batch if prev_layer is None else prev_layer.output\n",
    "                layer.forward(layer_input)\n",
    "            elif isinstance(layer, ActivationReLU):\n",
    "                layer.forward(prev_layer.output)\n",
    "            elif isinstance(layer, ActivationSoftmaxLossCategoricalCrossentropy):\n",
    "                loss = layer.forward(prev_layer.output, y_batch)\n",
    "            prev_layer = layer\n",
    "        return loss\n",
    "    \n",
    "    def back_propagation(self, y_batch):\n",
    "        layers_reversed = self.layers[::-1]\n",
    "        prev_layer = None\n",
    "        for layer in layers_reversed:\n",
    "            if isinstance(layer, ActivationSoftmaxLossCategoricalCrossentropy):\n",
    "                layer.backward(layer.output, y_batch)\n",
    "            elif isinstance(layer, LayerDense):\n",
    "                layer.backward(prev_layer.dinputs)\n",
    "            elif isinstance(layer, ActivationReLU):\n",
    "                layer.backward(prev_layer.dinputs)\n",
    "            prev_layer = layer\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, LayerDense):\n",
    "                self.optimizer.update_params(layer)\n",
    "    \n",
    "    def train(self, x, y, epochs, batch_size):\n",
    "        for i in range(epochs):\n",
    "            for j in range(0, len(x), batch_size):\n",
    "                x_batch = x[j:j+batch_size]\n",
    "                y_batch = y[j:j+batch_size]\n",
    "                loss = self.forward_propagation(x_batch, y_batch)\n",
    "                self.back_propagation(y_batch)\n",
    "                predictions = np.argmax(self.layers[-1].output, axis=1)\n",
    "                accuracy = np.mean(predictions == np.argmax(y_batch, axis=1))\n",
    "            print(f'epoch: {i}, ' + f'acc: {accuracy:.3f}, ' + f'loss: {loss:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T09:40:59.537862Z",
     "start_time": "2024-03-19T09:40:59.531991Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:19:34.567994Z",
     "start_time": "2024-03-11T19:18:47.764508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.850, loss: 22.761\n",
      "epoch: 1, acc: 0.900, loss: 16.954\n",
      "epoch: 2, acc: 0.933, loss: 14.287\n",
      "epoch: 3, acc: 0.933, loss: 12.722\n",
      "epoch: 4, acc: 0.933, loss: 11.038\n",
      "epoch: 5, acc: 0.933, loss: 9.593\n",
      "epoch: 6, acc: 0.967, loss: 8.075\n",
      "epoch: 7, acc: 0.983, loss: 7.208\n",
      "epoch: 8, acc: 0.983, loss: 6.795\n",
      "epoch: 9, acc: 0.983, loss: 6.644\n",
      "epoch: 10, acc: 0.983, loss: 6.723\n",
      "epoch: 11, acc: 0.967, loss: 6.794\n",
      "epoch: 12, acc: 0.967, loss: 6.826\n",
      "epoch: 13, acc: 0.967, loss: 7.018\n",
      "epoch: 14, acc: 0.967, loss: 7.150\n",
      "epoch: 15, acc: 0.950, loss: 7.320\n",
      "epoch: 16, acc: 0.950, loss: 7.388\n",
      "epoch: 17, acc: 0.950, loss: 7.435\n",
      "epoch: 18, acc: 0.933, loss: 7.360\n",
      "epoch: 19, acc: 0.933, loss: 7.373\n",
      "epoch: 20, acc: 0.950, loss: 7.370\n",
      "epoch: 21, acc: 0.967, loss: 7.266\n",
      "epoch: 22, acc: 0.967, loss: 7.148\n",
      "epoch: 23, acc: 0.967, loss: 7.019\n",
      "epoch: 24, acc: 0.983, loss: 6.901\n",
      "epoch: 25, acc: 0.983, loss: 6.767\n",
      "epoch: 26, acc: 0.983, loss: 6.684\n",
      "epoch: 27, acc: 0.983, loss: 6.504\n",
      "epoch: 28, acc: 0.983, loss: 6.420\n",
      "epoch: 29, acc: 0.983, loss: 6.366\n",
      "epoch: 30, acc: 0.983, loss: 6.276\n",
      "epoch: 31, acc: 0.983, loss: 6.208\n",
      "epoch: 32, acc: 0.983, loss: 6.176\n",
      "epoch: 33, acc: 0.983, loss: 6.135\n",
      "epoch: 34, acc: 0.983, loss: 6.190\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      9\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m60\u001B[39m\n\u001B[0;32m---> 11\u001B[0m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 43\u001B[0m, in \u001B[0;36mNetwork.train\u001B[0;34m(self, x, y, epochs, batch_size)\u001B[0m\n\u001B[1;32m     41\u001B[0m y_batch \u001B[38;5;241m=\u001B[39m y[j:j\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m     42\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_propagation(x_batch, y_batch)\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mback_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m predictions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39moutput, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     45\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(predictions \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_batch, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "Cell \u001B[0;32mIn[8], line 29\u001B[0m, in \u001B[0;36mNetwork.back_propagation\u001B[0;34m(self, y_batch)\u001B[0m\n\u001B[1;32m     27\u001B[0m     layer\u001B[38;5;241m.\u001B[39mbackward(layer\u001B[38;5;241m.\u001B[39moutput, y_batch)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer, LayerDense):\n\u001B[0;32m---> 29\u001B[0m     \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprev_layer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdinputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(layer, ActivationReLU):\n\u001B[1;32m     31\u001B[0m     layer\u001B[38;5;241m.\u001B[39mbackward(prev_layer\u001B[38;5;241m.\u001B[39mdinputs)\n",
      "Cell \u001B[0;32mIn[4], line 14\u001B[0m, in \u001B[0;36mLayerDense.backward\u001B[0;34m(self, d_values)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdweights \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs\u001B[38;5;241m.\u001B[39mT, d_values) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdbiases \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(d_values, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs)\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdinputs \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43md_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "network = Network([\n",
    "    LayerDense(784, 10),\n",
    "    ActivationReLU(),\n",
    "    LayerDense(10, 10),\n",
    "    ActivationSoftmaxLossCategoricalCrossentropy()\n",
    "], OptimizerSGD())\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 60\n",
    "\n",
    "network.train(x, y, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "test_sample_num = 9894\n",
    "x_test, num_inputs = read_mnist_images('mnist/t10k-images.idx3-ubyte')\n",
    "x_test_flat = x_test.reshape(-1, 784) / 255.\n",
    "y_test = one_hot_encode(read_mnist_labels('mnist/t10k-labels.idx1-ubyte'), 10)\n",
    "network.forward_propagation(x_test_flat, y_test)\n",
    "print(np.argmax(network.layers[-1].output[test_sample_num]))\n",
    "print(np.argmax(y_test[test_sample_num]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:20:00.612905Z",
     "start_time": "2024-03-11T19:20:00.573654Z"
    }
   },
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x134359250>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[9894], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:19:55.866261Z",
     "start_time": "2024-03-11T19:19:55.807099Z"
    }
   },
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
